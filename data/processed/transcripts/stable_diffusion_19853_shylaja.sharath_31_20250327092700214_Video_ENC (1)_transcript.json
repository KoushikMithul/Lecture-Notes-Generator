{
  "video_name": "stable_diffusion_19853_shylaja.sharath_31_20250327092700214_Video_ENC (1)",
  "video_path": "data/raw/videos/stable_diffusion_19853_shylaja.sharath_31_20250327092700214_Video_ENC (1).mp4",
  "duration_seconds": 3300.096,
  "transcript": [
    {
      "text": " types of inputs in generating of embeddings that is called as a multimodal LLM.",
      "start_time": 0.0,
      "end_time": 5.32
    },
    {
      "text": " So here clip accepts image text pairs, image text pairs.",
      "start_time": 5.32,
      "end_time": 15.12
    },
    {
      "text": " See there is slight deviation from the original idea that is it but it has become very popular.",
      "start_time": 15.12,
      "end_time": 22.4
    },
    {
      "text": " You must have heard about clip blip and all of that right but it became popular.",
      "start_time": 22.4,
      "end_time": 26.68
    },
    {
      "text": "",
      "start_time": 26.68,
      "end_time": 0.0
    },
    {
      "text": " What did they do? I will tell you now, just now.",
      "start_time": 1.0,
      "end_time": 2.0
    },
    {
      "text": " Just in a minute.",
      "start_time": 2.0,
      "end_time": 3.0
    },
    {
      "text": " So here they have used a vision transformer.",
      "start_time": 30.0,
      "end_time": 34.32
    },
    {
      "text": " They have used a vision transformer.",
      "start_time": 34.32,
      "end_time": 36.84
    },
    {
      "text": " What is a vision transformer?",
      "start_time": 36.84,
      "end_time": 37.84
    },
    {
      "text": " We have studied already.",
      "start_time": 37.84,
      "end_time": 39.04
    },
    {
      "text": " What is it?",
      "start_time": 39.04,
      "end_time": 42.4
    },
    {
      "text": " Given an image, it fits it into patches.",
      "start_time": 42.4,
      "end_time": 46.96
    },
    {
      "text": " Transformer it expects sequence.",
      "start_time": 46.96,
      "end_time": 47.96
    },
    {
      "text": " This you should remember forever.",
      "start_time": 47.96,
      "end_time": 51.16
    },
    {
      "text": " Transformer means it is a sequence to sequence model.",
      "start_time": 51.16,
      "end_time": 53.72
    },
    {
      "text": " We should give some sequence to transformer.",
      "start_time": 53.72,
      "end_time": 56.2
    },
    {
      "text": " To give a sequence, image is not a sequence basically.",
      "start_time": 56.2,
      "end_time": 59.4
    },
    {
      "text": "",
      "start_time": 59.4,
      "end_time": 30.0
    },
    {
      "text": " How do you convert?",
      "start_time": 30.64,
      "end_time": null
    },
    {
      "text": " an image into a sequence, piece it, scissor it and then make the sequence and produce",
      "start_time": 60.0,
      "end_time": 65.96
    },
    {
      "text": " that sequence. So, image sequence is given, image sequence is given and it produces image",
      "start_time": 65.96,
      "end_time": 73.32
    },
    {
      "text": " embeddings, image embeddings. This is one architecture used in clip. On the other side,",
      "start_time": 73.32,
      "end_time": 82.6
    },
    {
      "text": "",
      "start_time": 82.6,
      "end_time": 60.0
    },
    {
      "text": " uses GPT kind of architecture decoder, GPT type of decoder.",
      "start_time": 64.76,
      "end_time": null
    },
    {
      "text": " and text prompt is given and it produces text embeddings. Text embeddings are produced",
      "start_time": 90.0,
      "end_time": 100.44
    },
    {
      "text": " to architectures separately in the clip model and these image embeddings and text embeddings",
      "start_time": 100.44,
      "end_time": 107.56
    },
    {
      "text": " let us say we are giving the image of a cat, image of a cat and the text is also saying",
      "start_time": 107.56,
      "end_time": 114.24
    },
    {
      "text": "",
      "start_time": 114.24,
      "end_time": 90.0
    },
    {
      "text": " cat image, text is also saying cat image. So the embedding generated by this is the",
      "start_time": 97.0,
      "end_time": null
    },
    {
      "text": " these two should be close they have to match right it is a match pair image and text match",
      "start_time": 120.0,
      "end_time": 125.84
    },
    {
      "text": " pair so if it is not matching it will retrain saying that these embedding should come closer",
      "start_time": 125.84,
      "end_time": 131.72
    },
    {
      "text": " to each other so checks the cosine similarity between the two that is why it is called as",
      "start_time": 131.72,
      "end_time": 136.2
    },
    {
      "text": " contrastive learning cosine similarity between the text embedding and image embedding and",
      "start_time": 136.2,
      "end_time": 143.76
    },
    {
      "text": " if it is not close to one there is lot of error because we know that we have given matching",
      "start_time": 143.76,
      "end_time": 149.52
    },
    {
      "text": "",
      "start_time": 149.52,
      "end_time": 120.0
    },
    {
      "text": " Catty made it.",
      "start_time": 120.5,
      "end_time": null
    },
    {
      "text": " we gave and the text is also cat image the two embedding should be close if the two embeddings",
      "start_time": 150.0,
      "end_time": 155.8
    },
    {
      "text": " are not close then there is high loss, high loss will backtrane back propagate and train",
      "start_time": 155.8,
      "end_time": 161.4
    },
    {
      "text": " so that the loss between the two embeddings is reduced what does that mean it learns the",
      "start_time": 161.4,
      "end_time": 166.64
    },
    {
      "text": " equivalent text embedding and image embedding it brings them to same space that is what",
      "start_time": 166.64,
      "end_time": 172.07999999999998
    },
    {
      "text": " the clip is trying to learn suppose I give that this is a dog image dog image is a text",
      "start_time": 172.07999999999998,
      "end_time": 178.56
    },
    {
      "text": "",
      "start_time": 178.56,
      "end_time": 150.0
    },
    {
      "text": " from but what I am giving.",
      "start_time": 151.44,
      "end_time": null
    },
    {
      "text": " is a cat and now you check whether the embedding are really dissimilar or not. If they are",
      "start_time": 180.0,
      "end_time": 187.12
    },
    {
      "text": " actually very similar then there is again there is a loss. So you train so that they",
      "start_time": 187.12,
      "end_time": 191.98
    },
    {
      "text": " become far apart. So for similarity you can keep it 1 for dissimilarity you can keep it",
      "start_time": 191.98,
      "end_time": 197.24
    },
    {
      "text": " 0 any output you can keep. So if they are not close to this if they are similar they",
      "start_time": 197.24,
      "end_time": 201.64
    },
    {
      "text": " have to be close to 1. If they are not close to 1 there is a loss if they are dissimilar",
      "start_time": 201.64,
      "end_time": 207.04
    },
    {
      "text": "",
      "start_time": 207.04,
      "end_time": 180.0
    },
    {
      "text": " information they have to be close to 0. If they are not close to 0, then they will be",
      "start_time": 187.0,
      "end_time": null
    },
    {
      "text": " to 0 again there is a loss. So, like this they gave similar pairs dissimilar pairs like",
      "start_time": 210.0,
      "end_time": 215.44
    },
    {
      "text": " this a lot of may be 1 k 2 k 2 lakh I am saying 2 lakh images and then they trained this transformer",
      "start_time": 215.44,
      "end_time": 222.64
    },
    {
      "text": " this is how clip is trained. Now, once the clip is trained now you can give",
      "start_time": 222.64,
      "end_time": 227.6
    },
    {
      "text": " that just the text and the text embedding generated would be in the space similar to",
      "start_time": 227.6,
      "end_time": 233.76
    },
    {
      "text": " that of the image. Do you understand the difference between the bird embedding and this also text",
      "start_time": 233.76,
      "end_time": 238.76
    },
    {
      "text": "",
      "start_time": 238.76,
      "end_time": 210.0
    },
    {
      "text": " next time meeting it can do.",
      "start_time": 210.92,
      "end_time": null
    },
    {
      "text": " So, once the clip is ready you can just give text prompt and you can get the text embeddings.",
      "start_time": 240.0,
      "end_time": 247.4
    },
    {
      "text": " What is the difference between clips text embedding and birds, birds same text what is",
      "start_time": 247.4,
      "end_time": 255.36
    },
    {
      "text": " the difference the embedded same sentence let us say cat image cat image to bird cat",
      "start_time": 255.36,
      "end_time": 263.08
    },
    {
      "text": " image to clip if you give the embedding generated by the clip will be similar to image embedding",
      "start_time": 263.08,
      "end_time": 269.72
    },
    {
      "text": "",
      "start_time": 269.72,
      "end_time": 240.0
    },
    {
      "text": " Thanks, babe.",
      "start_time": 241.0,
      "end_time": null
    },
    {
      "text": " The two embeddings will not be same.",
      "start_time": 270.0,
      "end_time": 273.2
    },
    {
      "text": " The training tasks are different.",
      "start_time": 273.2,
      "end_time": 276.44
    },
    {
      "text": " Do you understand?",
      "start_time": 276.44,
      "end_time": 277.68
    },
    {
      "text": " The BERT has been trained only on missing word prediction.",
      "start_time": 277.68,
      "end_time": 281.16
    },
    {
      "text": " The way the embeddings are generated by BERT is totally different.",
      "start_time": 281.16,
      "end_time": 284.68
    },
    {
      "text": " For the same sentence, do you understand the difference and can you appreciate?",
      "start_time": 284.68,
      "end_time": 290.2
    },
    {
      "text": " It is very important on what they have been trained on, what is the task at which they",
      "start_time": 290.2,
      "end_time": 295.4
    },
    {
      "text": " are good at.",
      "start_time": 295.4,
      "end_time": 297.16
    },
    {
      "text": "",
      "start_time": 297.16,
      "end_time": 270.0
    },
    {
      "text": " based on that only they will produce embedding.",
      "start_time": 272.84,
      "end_time": null
    },
    {
      "text": " Although the sentences are same, the kind of embedding produced by BERT would be very",
      "start_time": 300.0,
      "end_time": 305.0
    },
    {
      "text": " different from the embedding produced by CLIP and the CLIP embedding would be close to image",
      "start_time": 305.0,
      "end_time": 311.08
    },
    {
      "text": " type of embedding.",
      "start_time": 311.08,
      "end_time": 313.12
    },
    {
      "text": " So you should know if you are operating in image related applications, the text prompt",
      "start_time": 313.12,
      "end_time": 317.28
    },
    {
      "text": " embedding should be close to image related embedding.",
      "start_time": 317.28,
      "end_time": 320.08
    },
    {
      "text": " You cannot use a BERT there.",
      "start_time": 320.08,
      "end_time": 322.36
    },
    {
      "text": " You understand when you give a text prompt and you want it to be converted into an embedding",
      "start_time": 322.36,
      "end_time": 327.12
    },
    {
      "text": "",
      "start_time": 327.12,
      "end_time": 300.0
    },
    {
      "text": " and you are using that for generating an image.",
      "start_time": 302.32,
      "end_time": null
    },
    {
      "text": " Don't you think we should use clip now?",
      "start_time": 330.0,
      "end_time": 333.0
    },
    {
      "text": " Do you understand what I am saying?",
      "start_time": 333.0,
      "end_time": 335.0
    },
    {
      "text": " So the kind of prompt you gave cat image, cat image, here also cat image but this produce",
      "start_time": 335.0,
      "end_time": 344.44
    },
    {
      "text": " 0.1, 0.2, this may produce 0.6, 0.5.",
      "start_time": 344.44,
      "end_time": 348.92
    },
    {
      "text": " The two embeddings are different because the training that has been given is different.",
      "start_time": 348.92,
      "end_time": 353.72
    },
    {
      "text": " You get what I am saying?",
      "start_time": 353.72,
      "end_time": 356.52
    },
    {
      "text": "",
      "start_time": 356.52,
      "end_time": 330.0
    },
    {
      "text": " The 0.6, 0.5 will be similar to that of image embedding which is\u2026",
      "start_time": 333.52,
      "end_time": null
    },
    {
      "text": " And if you are talking about image applications you should use such pre-trained models.",
      "start_time": 360.0,
      "end_time": 365.56
    },
    {
      "text": " Now you understand hopefully which pre-trained model you should choose is not just like that",
      "start_time": 365.56,
      "end_time": 371.28
    },
    {
      "text": " some pre-trained model.",
      "start_time": 371.28,
      "end_time": 373.28
    },
    {
      "text": " Your first understanding should be what is it trained on?",
      "start_time": 373.28,
      "end_time": 377.8
    },
    {
      "text": " Is it going to serve my purpose or not?",
      "start_time": 377.8,
      "end_time": 379.92
    },
    {
      "text": " Do you understand?",
      "start_time": 379.92,
      "end_time": 380.92
    },
    {
      "text": " Lot of pre-trained models are available.",
      "start_time": 380.92,
      "end_time": 384.92
    },
    {
      "text": " Just like that you cannot pick up something.",
      "start_time": 384.92,
      "end_time": 386.92
    },
    {
      "text": "",
      "start_time": 386.92,
      "end_time": 360.0
    },
    {
      "text": " I use the VGG, I use the ResNet like that you use.",
      "start_time": 362.68,
      "end_time": null
    },
    {
      "text": " It is not generic, you have to decide what task it is trained on whether it is going",
      "start_time": 390.0,
      "end_time": 395.32
    },
    {
      "text": " to suit my application or not.",
      "start_time": 395.32,
      "end_time": 397.92
    },
    {
      "text": " Then it will be closer not that the bird will not work but those embeddings will be far",
      "start_time": 397.92,
      "end_time": 402.16
    },
    {
      "text": " away from your image embeddings.",
      "start_time": 402.16,
      "end_time": 404.68
    },
    {
      "text": " They may not really serve the purpose so much.",
      "start_time": 404.68,
      "end_time": 407.08
    },
    {
      "text": " So that is the importance of which pre-trained model.",
      "start_time": 407.08,
      "end_time": 412.08
    },
    {
      "text": " Pre-training means that you should know the task on which it is pre-trained so that you",
      "start_time": 412.08,
      "end_time": 417.72
    },
    {
      "text": "",
      "start_time": 417.72,
      "end_time": 390.0
    },
    {
      "text": " know what kind of embedding get generated from",
      "start_time": 392.32,
      "end_time": null
    },
    {
      "text": " the pre-trained model and whether those embeddings will make sense in my application or not and",
      "start_time": 420.0,
      "end_time": 425.08
    },
    {
      "text": " based on that you should proceed further.",
      "start_time": 425.08,
      "end_time": 427.2
    },
    {
      "text": " Is this clear?",
      "start_time": 427.2,
      "end_time": 428.2
    },
    {
      "text": " Okay.",
      "start_time": 428.2,
      "end_time": 429.2
    },
    {
      "text": " So, is clip clear?",
      "start_time": 429.2,
      "end_time": 430.2
    },
    {
      "text": " So, the pre-trained clip model is used in generating text embedding.",
      "start_time": 430.2,
      "end_time": 435.52
    },
    {
      "text": " Why is clip used here?",
      "start_time": 435.52,
      "end_time": 438.16
    },
    {
      "text": " Because our job is to generate image.",
      "start_time": 438.16,
      "end_time": 440.2
    },
    {
      "text": " I want the text embedding close to image embedding.",
      "start_time": 440.2,
      "end_time": 442.76
    },
    {
      "text": " So, clip is used.",
      "start_time": 442.76,
      "end_time": 444.04
    },
    {
      "text": "",
      "start_time": 444.04,
      "end_time": 420.0
    },
    {
      "text": " So second step in the stable diffusion is to send this text from",
      "start_time": 427.0,
      "end_time": null
    },
    {
      "text": " to clip and generate text embeddings. This is the second step. Now the third step is",
      "start_time": 450.0,
      "end_time": 472.36
    },
    {
      "text": "",
      "start_time": 472.36,
      "end_time": 450.0
    },
    {
      "text": " third step, text time bidding and the latent vector.",
      "start_time": 455.76,
      "end_time": null
    },
    {
      "text": " is produced given to unit. The latent vector and the text embedding both are given to the",
      "start_time": 480.0,
      "end_time": 493.16
    },
    {
      "text": " unit architecture, both are inputs and what is the job of the unit? It produces noise",
      "start_time": 493.16,
      "end_time": 504.0
    },
    {
      "text": "",
      "start_time": 504.0,
      "end_time": 480.0
    },
    {
      "text": " prediction.",
      "start_time": 480.6,
      "end_time": null
    },
    {
      "text": " That is the third step in stable diffusion.",
      "start_time": 510.0,
      "end_time": 520.44
    },
    {
      "text": " Unit architecture receives two inputs latent vector with noise and then text embedding",
      "start_time": 520.44,
      "end_time": 532.76
    },
    {
      "text": "",
      "start_time": 532.76,
      "end_time": 510.0
    },
    {
      "text": " and produces noise predictions.",
      "start_time": 516.72,
      "end_time": null
    },
    {
      "text": " How is the text embedding going to help? Suppose text embedding is that of a car, text embedding",
      "start_time": 540.0,
      "end_time": 549.38
    },
    {
      "text": " is that of a cat. So the amount of noise that you have to remove, so if it is a car latent",
      "start_time": 549.38,
      "end_time": 556.94
    },
    {
      "text": " vector, I am writing the image itself, it is in car I do not know how to write, some",
      "start_time": 556.94,
      "end_time": 562.18
    },
    {
      "text": " car I am writing. This is a car, my cat and car both look similar. This is a cat.",
      "start_time": 562.18,
      "end_time": 569.9
    },
    {
      "text": "",
      "start_time": 569.9,
      "end_time": 540.0
    },
    {
      "text": " Thank you.",
      "start_time": 541.0,
      "end_time": null
    },
    {
      "text": " This is the car, horribly looking like car, not good at writing 3D diagram is looking",
      "start_time": 570.0,
      "end_time": 578.72
    },
    {
      "text": " like a house, some wheels I will put maybe it will look like a car.",
      "start_time": 578.72,
      "end_time": 586.16
    },
    {
      "text": " This is the car, this is the cat, okay.",
      "start_time": 586.16,
      "end_time": 590.2
    },
    {
      "text": " I am not showing it in late and trekker space, I am showing it in image space, okay.",
      "start_time": 590.2,
      "end_time": 595.32
    },
    {
      "text": "",
      "start_time": 595.32,
      "end_time": 570.0
    },
    {
      "text": " So the way I am adding noise here, I have added noise here.",
      "start_time": 574.68,
      "end_time": null
    },
    {
      "text": " noise and I am feeding that to unit I am feeding that to unit now the kind of the way you have",
      "start_time": 600.0,
      "end_time": 608.0
    },
    {
      "text": " to remove noise from car the way you have to remove noise from cat they are different",
      "start_time": 608.0,
      "end_time": 612.68
    },
    {
      "text": " do you understand where you have to remove that noise and where you have to remove noise",
      "start_time": 612.68,
      "end_time": 619.12
    },
    {
      "text": " from car they are two different so to guide that process this conditioning is used the",
      "start_time": 619.12,
      "end_time": 626.4
    },
    {
      "text": "",
      "start_time": 626.4,
      "end_time": 600.0
    },
    {
      "text": " Extend coding will help how to remove noise for",
      "start_time": 603.52,
      "end_time": null
    },
    {
      "text": " how to remove noise for car. Of course it is back propagated if the noise removed is",
      "start_time": 630.0,
      "end_time": 635.72
    },
    {
      "text": " not same as car noise removal then back propagation is done and error correction is done. But",
      "start_time": 635.72,
      "end_time": 641.92
    },
    {
      "text": " you need to understand that text embedding is conditioning the unit to say that you remove",
      "start_time": 641.92,
      "end_time": 648.32
    },
    {
      "text": " the noise from this image to make sure that car image is going to be visible.",
      "start_time": 648.32,
      "end_time": 653.16
    },
    {
      "text": " You remove the noise from this image so that the cat is going to come up. The kind of noise",
      "start_time": 653.16,
      "end_time": 658.6
    },
    {
      "text": "",
      "start_time": 658.6,
      "end_time": 630.0
    },
    {
      "text": " removal that you do from can.",
      "start_time": 631.4,
      "end_time": null
    },
    {
      "text": " that is not the same as noise removal that you do it from car.",
      "start_time": 660.0,
      "end_time": 663.32
    },
    {
      "text": " So, to guide that process this text embedding will help, but apart from that it is a black",
      "start_time": 663.32,
      "end_time": 668.2
    },
    {
      "text": " box it does there is magic it is the magic is always in the back propagation if it is",
      "start_time": 668.2,
      "end_time": 673.28
    },
    {
      "text": " not doing that correctly you are going to back propagate at least you know that there",
      "start_time": 673.28,
      "end_time": 677.36
    },
    {
      "text": " is error it is not doing it properly you know.",
      "start_time": 677.36,
      "end_time": 680.48
    },
    {
      "text": " So you back propagate and somehow it is able to converge to a point where car becomes visible",
      "start_time": 680.48,
      "end_time": 686.16
    },
    {
      "text": "",
      "start_time": 686.16,
      "end_time": 660.0
    },
    {
      "text": " inside unit but what it produces is how much not.",
      "start_time": 663.84,
      "end_time": null
    },
    {
      "text": " noise I should remove if it is carved noise. How much noise I should remove if it is that",
      "start_time": 690.0,
      "end_time": 695.72
    },
    {
      "text": " of a cat image and noise. So it predicts the noise based on the image and the text embedding.",
      "start_time": 695.72,
      "end_time": 702.76
    },
    {
      "text": " The noise to be removed is dependent on the kind of image that is going to be present.",
      "start_time": 702.76,
      "end_time": 708.8
    },
    {
      "text": " So that is the job of the unit. The unit architecture goes like this. This is convolutions, this",
      "start_time": 708.8,
      "end_time": 714.76
    },
    {
      "text": "",
      "start_time": 714.76,
      "end_time": 690.0
    },
    {
      "text": " is deconvolution this is a use factor that is why it is known as a use factor.",
      "start_time": 695.24,
      "end_time": null
    },
    {
      "text": " unit architecture okay and this is convolution and latent vector, from latent vector it tries",
      "start_time": 720.0,
      "end_time": 727.36
    },
    {
      "text": " to produce the image back and if it produces the image same as the original image with",
      "start_time": 727.36,
      "end_time": 732.64
    },
    {
      "text": " minus noise, noise will be predicted.",
      "start_time": 732.64,
      "end_time": 735.04
    },
    {
      "text": " So output of the convolution unit architecture is noise, not the noise removed image but",
      "start_time": 735.04,
      "end_time": 743.36
    },
    {
      "text": " it does that internally, it will remove the noise and it will compare all of that it does",
      "start_time": 743.36,
      "end_time": 747.52
    },
    {
      "text": "",
      "start_time": 747.52,
      "end_time": 720.0
    },
    {
      "text": " but the units in this section are not there.",
      "start_time": 727.0,
      "end_time": null
    },
    {
      "text": " example I am saying unit is not always used for that purpose. In this stable diffusion",
      "start_time": 750.0,
      "end_time": 754.94
    },
    {
      "text": " the purpose of unit is to predict how much noise is present in this image and that noise",
      "start_time": 754.94,
      "end_time": 761.72
    },
    {
      "text": " is varying even though you add similar amount of noise the noise removal is a process dependent",
      "start_time": 761.72,
      "end_time": 767.72
    },
    {
      "text": " on the structure within the image. So based on that it predicts the noise.",
      "start_time": 767.72,
      "end_time": 772.24
    },
    {
      "text": " So eventually when you expose this unit to many images many schedules of the noise of",
      "start_time": 772.24,
      "end_time": 779.44
    },
    {
      "text": "",
      "start_time": 779.44,
      "end_time": 750.0
    },
    {
      "text": " the same image.",
      "start_time": 750.6,
      "end_time": null
    },
    {
      "text": " image, it will eventually learn how to remove noise without disturbing the underlying structure",
      "start_time": 780.0,
      "end_time": 787.06
    },
    {
      "text": " that is what it learns. This is clear, this is the training process, this is clear, this",
      "start_time": 787.06,
      "end_time": 792.9
    },
    {
      "text": " is the unit architecture. So now we will have to proceed to the testing",
      "start_time": 792.9,
      "end_time": 798.72
    },
    {
      "text": "",
      "start_time": 798.72,
      "end_time": 780.0
    },
    {
      "text": " phase actually how it generates the image.",
      "start_time": 782.28,
      "end_time": null
    },
    {
      "text": " So, I produce image EIE then latent vector then add noise.",
      "start_time": 810.0,
      "end_time": 839.92
    },
    {
      "text": "",
      "start_time": 839.92,
      "end_time": 810.0
    },
    {
      "text": " Thank you.",
      "start_time": 812.0,
      "end_time": null
    },
    {
      "text": " Then unit.",
      "start_time": 840.0,
      "end_time": 847.0
    },
    {
      "text": " That's nice.",
      "start_time": 847.0,
      "end_time": 852.0
    },
    {
      "text": " Unit.",
      "start_time": 852.0,
      "end_time": 856.0
    },
    {
      "text": "",
      "start_time": 856.0,
      "end_time": 840.0
    },
    {
      "text": " and then we'll go back to the beginning. And then we'll go back to the beginning.",
      "start_time": 845.0,
      "end_time": 848.0
    },
    {
      "text": " And then we'll go back to the beginning.",
      "start_time": 848.0,
      "end_time": 853.0
    },
    {
      "text": " And then we'll go back to the beginning.",
      "start_time": 853.0,
      "end_time": 855.0
    },
    {
      "text": " And then we'll go back to the beginning.",
      "start_time": 855.0,
      "end_time": 858.0
    },
    {
      "text": " And then we'll go back to the beginning.",
      "start_time": 858.0,
      "end_time": 860.0
    },
    {
      "text": " And then we'll go back to the beginning.",
      "start_time": 860.0,
      "end_time": 862.0
    },
    {
      "text": " And then we'll go back to the beginning.",
      "start_time": 862.0,
      "end_time": 864.0
    },
    {
      "text": " And then we'll go back to the beginning.",
      "start_time": 864.0,
      "end_time": 866.0
    },
    {
      "text": " And then we'll go back to the beginning.",
      "start_time": 866.0,
      "end_time": 868.0
    },
    {
      "text": " That is your forward process.",
      "start_time": 870.0,
      "end_time": 880.64
    },
    {
      "text": " Image, go through VAE, produce the latent vector, then add the noise as per the schedule",
      "start_time": 880.64,
      "end_time": 888.4
    },
    {
      "text": " and then produce, send it to unit and text prompt, send it to clip, text embedding and",
      "start_time": 888.4,
      "end_time": 894.36
    },
    {
      "text": " then send it to unit, noise prediction.",
      "start_time": 894.36,
      "end_time": 897.6
    },
    {
      "text": "",
      "start_time": 897.6,
      "end_time": 870.0
    },
    {
      "text": " Now the second step, second step is to get the first step.",
      "start_time": 877.0,
      "end_time": null
    },
    {
      "text": " One step is the iteration for the same image, iteration for the same image starts here,",
      "start_time": 900.0,
      "end_time": 907.32
    },
    {
      "text": " another schedule of the noise of the same image, this process is not continued again",
      "start_time": 907.32,
      "end_time": 911.44
    },
    {
      "text": " for the same image.",
      "start_time": 911.44,
      "end_time": 913.76
    },
    {
      "text": " So, image 1, L1, L2 up to LT, different noises are added and then you continue this process.",
      "start_time": 913.76,
      "end_time": 925.36
    },
    {
      "text": "",
      "start_time": 925.36,
      "end_time": 900.0
    },
    {
      "text": " So that second image you take, then you take the second image start from here.",
      "start_time": 904.08,
      "end_time": null
    },
    {
      "text": " And then this is how you train it, is this clear?",
      "start_time": 930.0,
      "end_time": 935.4
    },
    {
      "text": " So once the LV is obtained, many schedules of the noise here you have to train on the",
      "start_time": 935.4,
      "end_time": 941.92
    },
    {
      "text": " same image.",
      "start_time": 941.92,
      "end_time": 942.92
    },
    {
      "text": " This is repeated many times and unit is trained.",
      "start_time": 942.92,
      "end_time": 947.88
    },
    {
      "text": " Then second image like this it gets trained on several lakhs of images with different",
      "start_time": 947.88,
      "end_time": 952.04
    },
    {
      "text": " noise schedules.",
      "start_time": 952.04,
      "end_time": 953.04
    },
    {
      "text": " So it is able to now predict how much noise is there in an image.",
      "start_time": 953.04,
      "end_time": 958.8
    },
    {
      "text": "",
      "start_time": 958.8,
      "end_time": 930.0
    },
    {
      "text": " That is a capability that...",
      "start_time": 931.16,
      "end_time": null
    },
    {
      "text": " unit is building. It is given a noisy image, it knows how to expect the amount of noise",
      "start_time": 960.0,
      "end_time": 969.36
    },
    {
      "text": " that is present in it without disturbing the structure. So, it produces that.",
      "start_time": 969.36,
      "end_time": 974.6
    },
    {
      "text": " Now, we will look at the reverse. So, in the reverse process, what is our objective finally?",
      "start_time": 974.6,
      "end_time": 986.4
    },
    {
      "text": "",
      "start_time": 986.4,
      "end_time": 960.0
    },
    {
      "text": " to generate an image.",
      "start_time": 962.0,
      "end_time": null
    },
    {
      "text": " So, prompt I will give you, I will say generate a cat image, generate a cat image, this is",
      "start_time": 990.0,
      "end_time": 1000.32
    },
    {
      "text": " the prompt as usual this will go through clip, this will give you text embedding, text embedding.",
      "start_time": 1000.32,
      "end_time": 1008.08
    },
    {
      "text": " This process remains the same during the generation phase, I will say to the stable diffusion",
      "start_time": 1008.08,
      "end_time": 1014.56
    },
    {
      "text": "",
      "start_time": 1014.56,
      "end_time": 990.0
    },
    {
      "text": " model generate a cat image. But now you have to generate",
      "start_time": 995.44,
      "end_time": null
    },
    {
      "text": " from the Gaussian distribution a latent vector. So a latent vector has to be generated which",
      "start_time": 1020.0,
      "end_time": 1026.68
    },
    {
      "text": " is a noisy latent vector, noisy latent vector based on a Gaussian distribution. It is proven",
      "start_time": 1026.68,
      "end_time": 1035.08
    },
    {
      "text": " that Gaussian noisy distribution sample would yield better images. Any other distribution",
      "start_time": 1035.08,
      "end_time": 1040.52
    },
    {
      "text": " you could have taken but that is for your experimentation. But a noisy latent vector",
      "start_time": 1040.52,
      "end_time": 1044.76
    },
    {
      "text": "",
      "start_time": 1044.76,
      "end_time": 1020.0
    },
    {
      "text": " has to be created from a Gaussian distribution sample. One sample has to be generated.",
      "start_time": 1025.0,
      "end_time": null
    },
    {
      "text": " So, that you give it to already trained unit, already trained unit.",
      "start_time": 1050.0,
      "end_time": 1056.92
    },
    {
      "text": " So, there is text embedding, it is not simply removing some noise.",
      "start_time": 1056.92,
      "end_time": 1061.72
    },
    {
      "text": " So, this predicts what, how much noise is there in the latent vector based on the text",
      "start_time": 1061.72,
      "end_time": 1070.04
    },
    {
      "text": " embedding, that is a beauty, it is not just noise.",
      "start_time": 1070.04,
      "end_time": 1074.32
    },
    {
      "text": " So, it is conditioned based on this.",
      "start_time": 1074.32,
      "end_time": 1076.76
    },
    {
      "text": "",
      "start_time": 1076.76,
      "end_time": 1050.0
    },
    {
      "text": " So how much is how much noise is there in this latent vector?",
      "start_time": 1053.16,
      "end_time": null
    },
    {
      "text": " vector based on this embedding. So, it predicts the noise, predicts the noise N1. Next what",
      "start_time": 1080.0,
      "end_time": 1091.16
    },
    {
      "text": " you should do? I have not a generated image, I have just predicted the noise that is present",
      "start_time": 1091.16,
      "end_time": 1097.04
    },
    {
      "text": " in latent vector based on my text embedding guidance. Now, I am supposed to subtract this",
      "start_time": 1097.04,
      "end_time": 1103.76
    },
    {
      "text": "",
      "start_time": 1103.76,
      "end_time": 1080.0
    },
    {
      "text": " noise n 1 from this l 1 this is l 1. So, l 1 minus n 1.",
      "start_time": 1086.26,
      "end_time": null
    },
    {
      "text": " will produce L2, L1 minus N1 will produce L2 and what I should do now? This is the reverse",
      "start_time": 1110.0,
      "end_time": 1120.96
    },
    {
      "text": " diffusion process, pure noise image is converted into a slightly better picture now which is",
      "start_time": 1120.96,
      "end_time": 1126.36
    },
    {
      "text": " L2. This is pure noise image, pure noise vector and this is better quality less slightly",
      "start_time": 1126.36,
      "end_time": 1137.34
    },
    {
      "text": "",
      "start_time": 1137.34,
      "end_time": 1110.0
    },
    {
      "text": " Ready?",
      "start_time": 1111.0,
      "end_time": null
    },
    {
      "text": " less than noise compared to L1 slightly lesser noise because we have subtracted this noise",
      "start_time": 1140.0,
      "end_time": 1148.0
    },
    {
      "text": " okay. Now I am going to feed L2 but your text form continues to be the same. Now I feed",
      "start_time": 1148.0,
      "end_time": 1157.92
    },
    {
      "text": " L2 so again noise is predicted this time it is N2. So now what I should do L2-N2 you produce",
      "start_time": 1157.92,
      "end_time": 1165.68
    },
    {
      "text": "",
      "start_time": 1165.68,
      "end_time": 1140.0
    },
    {
      "text": " This you do it for several steps.",
      "start_time": 1143.16,
      "end_time": null
    },
    {
      "text": " Do you understand?",
      "start_time": 1170.0,
      "end_time": 1172.2
    },
    {
      "text": " You do this for several steps.",
      "start_time": 1172.2,
      "end_time": 1174.52
    },
    {
      "text": " When you do this for several steps, you may get LT.",
      "start_time": 1174.52,
      "end_time": 1178.72
    },
    {
      "text": " Finally LT, some T steps you have done.",
      "start_time": 1178.72,
      "end_time": 1184.32
    },
    {
      "text": " So first time pure noise vector, you feed it to unit, produce, predict the noise and subtract",
      "start_time": 1184.32,
      "end_time": 1192.0
    },
    {
      "text": " the noise from L1 and then feed the lesser noise latent vector back again to unit.",
      "start_time": 1192.0,
      "end_time": 1198.08
    },
    {
      "text": "",
      "start_time": 1198.08,
      "end_time": 1170.0
    },
    {
      "text": " it will predict the noise like this.",
      "start_time": 1171.92,
      "end_time": null
    },
    {
      "text": " if you keep on doing for several steps may be t steps final latent vector you are satisfied",
      "start_time": 1200.0,
      "end_time": 1205.36
    },
    {
      "text": " may be after 100 steps you are satisfied with the latent vector LT but that is not an image.",
      "start_time": 1205.36,
      "end_time": 1210.8
    },
    {
      "text": " LT is the final latent vector generated out of the last noise removal LT is your final",
      "start_time": 1210.8,
      "end_time": 1217.08
    },
    {
      "text": " latent vector what is the next step? LT should be fed to decoder of VAE you should feed it",
      "start_time": 1217.08,
      "end_time": 1225.24
    },
    {
      "text": "",
      "start_time": 1225.24,
      "end_time": 1200.0
    },
    {
      "text": " to decoder of VAE to generate the",
      "start_time": 1204.76,
      "end_time": null
    },
    {
      "text": " actual image cat. These are the steps, is the process clear?",
      "start_time": 1230.0,
      "end_time": 1255.0
    },
    {
      "text": "",
      "start_time": 1255.0,
      "end_time": 1230.0
    },
    {
      "text": " Thank you.",
      "start_time": 1237.0,
      "end_time": null
    },
    {
      "text": " This is called as stable diffusion using latent diffusion models.",
      "start_time": 1260.0,
      "end_time": 1278.2
    },
    {
      "text": " I will give you a minute time now see whether you understood all the steps that I explained.",
      "start_time": 1278.2,
      "end_time": 1283.0
    },
    {
      "text": " What happens during training?",
      "start_time": 1283.0,
      "end_time": 1284.6
    },
    {
      "text": " What happens during testing or generation?",
      "start_time": 1284.6,
      "end_time": 1286.8
    },
    {
      "text": " Testing is generation.",
      "start_time": 1286.8,
      "end_time": 1288.2
    },
    {
      "text": "",
      "start_time": 1288.2,
      "end_time": 1260.0
    },
    {
      "text": " They are two different steps.",
      "start_time": 1262.0,
      "end_time": null
    },
    {
      "text": " What is for, see you should understand, answer these questions, what is diffusion, what is",
      "start_time": 1290.0,
      "end_time": 1294.78
    },
    {
      "text": " forward diffusion, what is reverse diffusion, characteristic equation related to diffusion,",
      "start_time": 1294.78,
      "end_time": 1300.48
    },
    {
      "text": " these 5 things related to diffusion.",
      "start_time": 1300.48,
      "end_time": 1302.88
    },
    {
      "text": " Then what is latent diffusion and how latent diffusion is used in stable diffusion.",
      "start_time": 1302.88,
      "end_time": 1308.48
    },
    {
      "text": " Stable diffusion is a image generation engine.",
      "start_time": 1308.48,
      "end_time": 1311.2
    },
    {
      "text": " To do that it uses 3 steps, what is VAE, what is its role, what is the encoder of VAE, what",
      "start_time": 1311.2,
      "end_time": 1318.36
    },
    {
      "text": "",
      "start_time": 1318.36,
      "end_time": 1290.0
    },
    {
      "text": " What is the decoder of VIA?",
      "start_time": 1291.3,
      "end_time": null
    },
    {
      "text": " Then you should know the second step of VAE, I mean second step of stable diffusion which",
      "start_time": 1320.0,
      "end_time": 1324.92
    },
    {
      "text": " is clip.",
      "start_time": 1324.92,
      "end_time": 1325.92
    },
    {
      "text": " What is a clip which is a multi-modal LLM, what it does, how it is trained, what is it",
      "start_time": 1325.92,
      "end_time": 1330.74
    },
    {
      "text": " good at, how the embeddings are created, all of that in the clip.",
      "start_time": 1330.74,
      "end_time": 1334.94
    },
    {
      "text": " And then clip is used for text embeddings and how text embedding at this is used for",
      "start_time": 1334.94,
      "end_time": 1339.58
    },
    {
      "text": " unit, how the noise prediction happens, how the unit is built during training phase to",
      "start_time": 1339.58,
      "end_time": 1344.66
    },
    {
      "text": " predict noise that is training, then generation.",
      "start_time": 1344.66,
      "end_time": 1347.58
    },
    {
      "text": "",
      "start_time": 1347.58,
      "end_time": 1320.0
    },
    {
      "text": " how the unit is fed with Gaussian.",
      "start_time": 1322.44,
      "end_time": null
    },
    {
      "text": " latent vector that is generated noise vector and the text prompt embedding and how that",
      "start_time": 1350.0,
      "end_time": 1355.06
    },
    {
      "text": " is fed, noise is predicted, subtract it latent vector, feed it again, feed it again, feed",
      "start_time": 1355.06,
      "end_time": 1360.7
    },
    {
      "text": " it again, subtract feed it, subtract feed it and then produce final latent vector then",
      "start_time": 1360.7,
      "end_time": 1365.1
    },
    {
      "text": " to the decoder and then produce the image. This is the full step. So figure out whether",
      "start_time": 1365.1,
      "end_time": 1369.5
    },
    {
      "text": "",
      "start_time": 1369.5,
      "end_time": 1350.0
    },
    {
      "text": " you understand all of these steps.",
      "start_time": 1360.16,
      "end_time": null
    },
    {
      "text": " If you understand all of that I said today, you will be able to answer properly the examinations.",
      "start_time": 1380.0,
      "end_time": 1393.04
    },
    {
      "text": " Everything about stable decision I have completely explained, this is all you need to know.",
      "start_time": 1393.04,
      "end_time": 1397.64
    },
    {
      "text": "",
      "start_time": 1397.64,
      "end_time": 1380.0
    },
    {
      "text": " I will just come get my laptop you can take a break also.",
      "start_time": 1392.2,
      "end_time": null
    },
    {
      "text": " I'm going to go back to the room.",
      "start_time": 1410.0,
      "end_time": 1417.0
    },
    {
      "text": " Okay.",
      "start_time": 1440.0,
      "end_time": 1442.0
    },
    {
      "text": " I'm going to go back to the car.",
      "start_time": 1470.0,
      "end_time": 1477.0
    },
    {
      "text": " I'm going to go back to the",
      "start_time": 1500.0,
      "end_time": 1502.0
    },
    {
      "text": " back of the",
      "start_time": 1502.0,
      "end_time": 1504.0
    },
    {
      "text": " back of the",
      "start_time": 1504.0,
      "end_time": 1506.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1506.0,
      "end_time": 1508.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1508.0,
      "end_time": 1510.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1510.0,
      "end_time": 1512.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1512.0,
      "end_time": 1514.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1514.0,
      "end_time": 1516.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1516.0,
      "end_time": 1518.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1518.0,
      "end_time": 1520.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1520.0,
      "end_time": 1522.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1522.0,
      "end_time": 1524.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1524.0,
      "end_time": 1526.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1526.0,
      "end_time": 1528.0
    },
    {
      "text": "",
      "start_time": 1528.0,
      "end_time": 1500.0
    },
    {
      "text": " Thank you.",
      "start_time": 1502.0,
      "end_time": null
    },
    {
      "text": " Okay.",
      "start_time": 1530.0,
      "end_time": 1532.0
    },
    {
      "text": " .",
      "start_time": 1560.0,
      "end_time": 1567.0
    },
    {
      "text": " The",
      "start_time": 1590.0,
      "end_time": 1592.0
    },
    {
      "text": " I'm going to go back to the car.",
      "start_time": 1620.0,
      "end_time": 1627.0
    },
    {
      "text": " I'm",
      "start_time": 1650.0,
      "end_time": 1657.0
    },
    {
      "text": " I'm",
      "start_time": 1657.0,
      "end_time": 1664.0
    },
    {
      "text": " I'm",
      "start_time": 1664.0,
      "end_time": 1671.0
    },
    {
      "text": " I'm",
      "start_time": 1671.0,
      "end_time": 1678.0
    },
    {
      "text": "",
      "start_time": 1678.0,
      "end_time": 1650.0
    },
    {
      "text": " Thank you.",
      "start_time": 1652.0,
      "end_time": null
    },
    {
      "text": " Thank you.",
      "start_time": 1680.0,
      "end_time": 1687.0
    },
    {
      "text": " .",
      "start_time": 1710.0,
      "end_time": 1717.0
    },
    {
      "text": " .",
      "start_time": 1717.0,
      "end_time": 1724.0
    },
    {
      "text": " .",
      "start_time": 1724.0,
      "end_time": 1730.0
    },
    {
      "text": " .",
      "start_time": 1730.0,
      "end_time": 1739.0
    },
    {
      "text": "",
      "start_time": 1739.0,
      "end_time": 1710.0
    },
    {
      "text": " Thank you.",
      "start_time": 1711.0,
      "end_time": null
    },
    {
      "text": " I'm going to go back to the",
      "start_time": 1740.0,
      "end_time": 1742.0
    },
    {
      "text": " back of the",
      "start_time": 1742.0,
      "end_time": 1744.0
    },
    {
      "text": " back of the",
      "start_time": 1744.0,
      "end_time": 1746.0
    },
    {
      "text": " back of the back of the",
      "start_time": 1746.0,
      "end_time": 1748.0
    },
    {
      "text": " back of the back of the",
      "start_time": 1748.0,
      "end_time": 1750.0
    },
    {
      "text": " back of the back of the",
      "start_time": 1750.0,
      "end_time": 1752.0
    },
    {
      "text": " back of the back of the",
      "start_time": 1752.0,
      "end_time": 1754.0
    },
    {
      "text": " back of the back of the",
      "start_time": 1754.0,
      "end_time": 1756.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1756.0,
      "end_time": 1758.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1758.0,
      "end_time": 1760.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1760.0,
      "end_time": 1762.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1762.0,
      "end_time": 1764.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1764.0,
      "end_time": 1766.0
    },
    {
      "text": " back of the back of the back of the",
      "start_time": 1766.0,
      "end_time": 1768.0
    },
    {
      "text": "",
      "start_time": 1768.0,
      "end_time": 1740.0
    },
    {
      "text": " Thank you.",
      "start_time": 1742.0,
      "end_time": null
    },
    {
      "text": " Please answer your attendance.",
      "start_time": 1770.0,
      "end_time": 1777.0
    },
    {
      "text": " Anmita, Aryan, Bhavana, Bhavana, Bhumika, Bhumika, Hemchandra, Chaitra, Chandana, Chandana,",
      "start_time": 1800.0,
      "end_time": 1819.8
    },
    {
      "text": "",
      "start_time": 1819.8,
      "end_time": 1800.0
    },
    {
      "text": " Chinmai, Darshan, Dhruv, Dhiya, Fiza, Kaorish,",
      "start_time": 1810.28,
      "end_time": null
    },
    {
      "text": " Harshil, Harshini, Hemanta, Ritika, Ishaan, Vignesh, Amrita, Kishore, Manoj, Mohit,",
      "start_time": 1830.0,
      "end_time": 1854.48
    },
    {
      "text": "",
      "start_time": 1854.48,
      "end_time": 1830.0
    },
    {
      "text": " Yes. Nikhil.",
      "start_time": 1831.0,
      "end_time": 1832.0
    },
    {
      "text": " Nisha.",
      "start_time": 1832.0,
      "end_time": 1833.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1833.0,
      "end_time": 1834.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1834.0,
      "end_time": 1835.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1835.0,
      "end_time": 1836.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1836.0,
      "end_time": 1837.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1837.0,
      "end_time": 1838.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1838.0,
      "end_time": 1839.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1839.0,
      "end_time": 1840.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1840.0,
      "end_time": 1841.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1841.0,
      "end_time": 1842.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1842.0,
      "end_time": 1843.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1843.0,
      "end_time": 1844.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1844.0,
      "end_time": 1845.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1845.0,
      "end_time": 1846.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1846.0,
      "end_time": 1847.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1847.0,
      "end_time": 1848.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1848.0,
      "end_time": 1849.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1849.0,
      "end_time": 1850.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1850.0,
      "end_time": 1851.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1851.0,
      "end_time": 1852.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1852.0,
      "end_time": 1853.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1853.0,
      "end_time": 1854.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1854.0,
      "end_time": 1855.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1855.0,
      "end_time": 1856.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1856.0,
      "end_time": 1857.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1857.0,
      "end_time": 1858.0
    },
    {
      "text": " Nikhil.",
      "start_time": 1858.0,
      "end_time": 1859.0
    },
    {
      "text": " Vishan, Chiru, Piyush, Rajul, Ranjal, Priyanka, Priyansh, Diksha, Rajit, Rahul,",
      "start_time": 1860.0,
      "end_time": 1889.88
    },
    {
      "text": "",
      "start_time": 1889.88,
      "end_time": 1860.0
    },
    {
      "text": " Thank you.",
      "start_time": 1862.0,
      "end_time": null
    },
    {
      "text": " Rohan, Kachi, Sri Hari, Sushrit, Siddharth, Siddharth, Saurabh, Sujay, Sujit, Sukhi,",
      "start_time": 1890.0,
      "end_time": 1914.8
    },
    {
      "text": "",
      "start_time": 1914.8,
      "end_time": 1890.0
    },
    {
      "text": " Sai Shridhar, Jagapati, Yash Nagraj",
      "start_time": 1895.0,
      "end_time": null
    },
    {
      "text": " Asha Svii Ni, Arpita, Sarvad Nya, Ishwari, Nithika, Nithika B. Vinay,",
      "start_time": 1920.0,
      "end_time": 1938.84
    },
    {
      "text": "",
      "start_time": 1938.84,
      "end_time": 1920.0
    },
    {
      "text": " Yes, Akshay, Om Mathur, Mithun Kumar, Pushkar.",
      "start_time": 1931.0,
      "end_time": null
    },
    {
      "text": " Smira, baceuraj?",
      "start_time": 1950.0,
      "end_time": 1953.0
    },
    {
      "text": " and",
      "start_time": 1980.0,
      "end_time": 1987.0
    },
    {
      "text": " the",
      "start_time": 2010.0,
      "end_time": 2017.0
    },
    {
      "text": " The correct equation is the given letter.",
      "start_time": 2040.0,
      "end_time": 2047.0
    },
    {
      "text": " The correct equation is given letter for the equation.",
      "start_time": 2047.0,
      "end_time": 2050.0
    },
    {
      "text": " I will put the same as the one in the hand.",
      "start_time": 2050.0,
      "end_time": 2065.0
    },
    {
      "text": "",
      "start_time": 2065.0,
      "end_time": 2040.0
    },
    {
      "text": " and we are like renewing the noise from the lately matter. How do you know how many times we had to...",
      "start_time": 2043.0,
      "end_time": 2045.0
    },
    {
      "text": " like do we check it with me or like is it a hyper parameter?",
      "start_time": 2070.0,
      "end_time": 2073.72
    },
    {
      "text": " That is a hyper parameter.",
      "start_time": 2073.72,
      "end_time": 2075.22
    },
    {
      "text": " How many, what is the noise schedule that you have to decide?",
      "start_time": 2075.22,
      "end_time": 2078.22
    },
    {
      "text": " How come Saurabh shifted there?",
      "start_time": 2100.0,
      "end_time": 2129.92
    },
    {
      "text": "",
      "start_time": 2129.92,
      "end_time": 2100.0
    },
    {
      "text": " Thank you.",
      "start_time": 2101.0,
      "end_time": null
    },
    {
      "text": " After the paper presents, after that he is there only.",
      "start_time": 2130.0,
      "end_time": 2137.0
    },
    {
      "text": " No one present, why?",
      "start_time": 2137.0,
      "end_time": 2146.0
    },
    {
      "text": " No.",
      "start_time": 2146.0,
      "end_time": 2148.0
    },
    {
      "text": " Because I wrote, I knew that if I write an email like that it would happen.",
      "start_time": 2148.0,
      "end_time": 2157.0
    },
    {
      "text": "",
      "start_time": 2157.0,
      "end_time": 2130.0
    },
    {
      "text": " There will be no control.",
      "start_time": 2132.56,
      "end_time": null
    },
    {
      "text": " If I do not inform also it is not correct, but I knew that if I inform many will skip.",
      "start_time": 2160.0,
      "end_time": 2174.56
    },
    {
      "text": " But that was 11.30 am now, but in between they skipped.",
      "start_time": 2174.56,
      "end_time": 2181.92
    },
    {
      "text": " In between also they skipped is it.",
      "start_time": 2181.92,
      "end_time": 2185.24
    },
    {
      "text": "",
      "start_time": 2185.24,
      "end_time": 2160.0
    },
    {
      "text": " Good morning, you...",
      "start_time": 2164.64,
      "end_time": null
    },
    {
      "text": " No, 11.30, no, because morning you had to come.",
      "start_time": 2190.0,
      "end_time": 2215.48
    },
    {
      "text": "",
      "start_time": 2215.48,
      "end_time": 2190.0
    },
    {
      "text": " Thank you.",
      "start_time": 2191.0,
      "end_time": null
    },
    {
      "text": " I'm going to go back to the",
      "start_time": 2220.0,
      "end_time": 2222.0
    },
    {
      "text": " room.",
      "start_time": 2222.0,
      "end_time": 2224.0
    },
    {
      "text": " I'm going to go back to the",
      "start_time": 2224.0,
      "end_time": 2226.0
    },
    {
      "text": " room.",
      "start_time": 2226.0,
      "end_time": 2228.0
    },
    {
      "text": " I'm going to go back to the",
      "start_time": 2228.0,
      "end_time": 2230.0
    },
    {
      "text": " room.",
      "start_time": 2230.0,
      "end_time": 2232.0
    },
    {
      "text": " I'm going to go back to the",
      "start_time": 2232.0,
      "end_time": 2234.0
    },
    {
      "text": " room.",
      "start_time": 2234.0,
      "end_time": 2236.0
    },
    {
      "text": " I'm going to go back to the",
      "start_time": 2236.0,
      "end_time": 2238.0
    },
    {
      "text": " room.",
      "start_time": 2238.0,
      "end_time": 2240.0
    },
    {
      "text": " I'm going to go back to the",
      "start_time": 2240.0,
      "end_time": 2242.0
    },
    {
      "text": " room.",
      "start_time": 2242.0,
      "end_time": 2244.0
    },
    {
      "text": " I'm going to go back to the",
      "start_time": 2244.0,
      "end_time": 2246.0
    },
    {
      "text": " room.",
      "start_time": 2246.0,
      "end_time": 2248.0
    },
    {
      "text": "",
      "start_time": 2248.0,
      "end_time": 2220.0
    },
    {
      "text": " Thank you.",
      "start_time": 2222.0,
      "end_time": null
    },
    {
      "text": " Thank you.",
      "start_time": 2250.0,
      "end_time": 2257.0
    },
    {
      "text": " Thank you.",
      "start_time": 2280.0,
      "end_time": 2287.0
    },
    {
      "text": " .",
      "start_time": 2310.0,
      "end_time": 2317.0
    },
    {
      "text": " .",
      "start_time": 2317.0,
      "end_time": 2324.0
    },
    {
      "text": " .",
      "start_time": 2324.0,
      "end_time": 2331.0
    },
    {
      "text": " .",
      "start_time": 2331.0,
      "end_time": 2338.0
    },
    {
      "text": "",
      "start_time": 2338.0,
      "end_time": 2310.0
    },
    {
      "text": " Thank you.",
      "start_time": 2312.0,
      "end_time": null
    },
    {
      "text": " the",
      "start_time": 2340.0,
      "end_time": 2347.0
    },
    {
      "text": " I'm not sure.",
      "start_time": 2370.0,
      "end_time": 2372.0
    },
    {
      "text": " The",
      "start_time": 2400.0,
      "end_time": 2402.0
    },
    {
      "text": " the",
      "start_time": 2430.0,
      "end_time": 2437.0
    },
    {
      "text": " Thank you.",
      "start_time": 2460.0,
      "end_time": 2467.0
    },
    {
      "text": " Thank you.",
      "start_time": 2490.0,
      "end_time": 2497.0
    },
    {
      "text": " the",
      "start_time": 2520.0,
      "end_time": 2527.0
    },
    {
      "text": " the",
      "start_time": 2550.0,
      "end_time": 2557.0
    },
    {
      "text": " So, let us look at this continue there is a stable diffusion demonstration let us look",
      "start_time": 2580.0,
      "end_time": 2603.64
    },
    {
      "text": "",
      "start_time": 2603.64,
      "end_time": 2580.0
    },
    {
      "text": " get that.",
      "start_time": 2586.64,
      "end_time": null
    },
    {
      "text": " So, this is the hugging phase demonstration site. So, we will say classroom with a teacher.",
      "start_time": 2610.0,
      "end_time": 2628.76
    },
    {
      "text": " I am giving the text from I told you it goes through the clip. So, I am asking it to generate",
      "start_time": 2628.76,
      "end_time": 2634.6
    },
    {
      "text": "",
      "start_time": 2634.6,
      "end_time": 2610.0
    },
    {
      "text": " classroom with a teacher. You are all doubt.",
      "start_time": 2612.0,
      "end_time": 2614.0
    },
    {
      "text": " Again I will run it.",
      "start_time": 2614.0,
      "end_time": 2616.0
    },
    {
      "text": " I'm going to turn it off.",
      "start_time": 2640.0,
      "end_time": 2647.0
    },
    {
      "text": " Wifi issues are there.",
      "start_time": 2670.0,
      "end_time": 2677.0
    },
    {
      "text": " Wifi is gone then.",
      "start_time": 2677.0,
      "end_time": 2690.0
    },
    {
      "text": "",
      "start_time": 2690.0,
      "end_time": 2670.0
    },
    {
      "text": " Wifi is gone then",
      "start_time": 2675.0,
      "end_time": null
    },
    {
      "text": " the",
      "start_time": 2700.0,
      "end_time": 2707.0
    },
    {
      "text": " Hello.",
      "start_time": 2730.0,
      "end_time": 2740.0
    },
    {
      "text": " Hello.",
      "start_time": 2740.0,
      "end_time": 2750.0
    },
    {
      "text": " Hello.",
      "start_time": 2750.0,
      "end_time": 2751.0
    },
    {
      "text": " Hello.",
      "start_time": 2751.0,
      "end_time": 2752.0
    },
    {
      "text": " Hello.",
      "start_time": 2752.0,
      "end_time": 2753.0
    },
    {
      "text": " Hello.",
      "start_time": 2753.0,
      "end_time": 2754.0
    },
    {
      "text": " Hello.",
      "start_time": 2754.0,
      "end_time": 2755.0
    },
    {
      "text": " Hello.",
      "start_time": 2755.0,
      "end_time": 2756.0
    },
    {
      "text": " Hello.",
      "start_time": 2756.0,
      "end_time": 2757.0
    },
    {
      "text": " Hello.",
      "start_time": 2757.0,
      "end_time": 2758.0
    },
    {
      "text": " Hello.",
      "start_time": 2758.0,
      "end_time": 2759.0
    },
    {
      "text": "",
      "start_time": 2759.0,
      "end_time": 2730.0
    },
    {
      "text": " I don't know.",
      "start_time": 2731.0,
      "end_time": null
    },
    {
      "text": " classroom normally 4th floor",
      "start_time": 2760.0,
      "end_time": 2762.0
    },
    {
      "text": " then demo mode is not working",
      "start_time": 2764.0,
      "end_time": 2766.0
    },
    {
      "text": " the",
      "start_time": 2790.0,
      "end_time": 2797.0
    },
    {
      "text": " Thank you.",
      "start_time": 2820.0,
      "end_time": 2827.0
    },
    {
      "text": " I'm",
      "start_time": 2850.0,
      "end_time": 2852.0
    },
    {
      "text": " the",
      "start_time": 2880.0,
      "end_time": 2887.0
    },
    {
      "text": " Thank you.",
      "start_time": 2910.0,
      "end_time": 2917.0
    },
    {
      "text": " It is not working.",
      "start_time": 2940.0,
      "end_time": 2964.32
    },
    {
      "text": "",
      "start_time": 2964.32,
      "end_time": 2940.0
    },
    {
      "text": " spot is also not working.",
      "start_time": 2942.0,
      "end_time": null
    },
    {
      "text": " Thank you.",
      "start_time": 2970.0,
      "end_time": 2977.0
    },
    {
      "text": " In the meantime, can I have your attention?",
      "start_time": 3000.0,
      "end_time": 3016.0
    },
    {
      "text": " I think this is already cached so it is appearing, the network is down so I am not able to connect",
      "start_time": 3016.0,
      "end_time": 3021.08
    },
    {
      "text": " to hotspot also.",
      "start_time": 3021.08,
      "end_time": 3022.08
    },
    {
      "text": "",
      "start_time": 3022.08,
      "end_time": 3000.0
    },
    {
      "text": " So, this is the stable diffusion stable art website.",
      "start_time": 3006.4,
      "end_time": null
    },
    {
      "text": " So this is the forward diffusion process.",
      "start_time": 3030.0,
      "end_time": 3033.32
    },
    {
      "text": " So cat image dog image forward diffusion this is the noise.",
      "start_time": 3033.32,
      "end_time": 3037.72
    },
    {
      "text": " So you can see that forward diffusion this is how it works.",
      "start_time": 3037.72,
      "end_time": 3042.24
    },
    {
      "text": " Are you able to see this?",
      "start_time": 3042.24,
      "end_time": 3046.16
    },
    {
      "text": " So cat is slowly blurred and you get a noisy image and in the reverse diffusion now it",
      "start_time": 3046.16,
      "end_time": 3052.72
    },
    {
      "text": "",
      "start_time": 3052.72,
      "end_time": 3030.0
    },
    {
      "text": " It is not cashed.",
      "start_time": 3034.0,
      "end_time": null
    },
    {
      "text": " Thank you.",
      "start_time": 3060.0,
      "end_time": 3067.0
    },
    {
      "text": " Okay.",
      "start_time": 3090.0,
      "end_time": 3097.0
    },
    {
      "text": " Okay",
      "start_time": 3120.0,
      "end_time": 3122.0
    },
    {
      "text": " There are classes for Manaka",
      "start_time": 3124.0,
      "end_time": 3126.0
    },
    {
      "text": " Your hotspot can I connect?",
      "start_time": 3131.0,
      "end_time": 3133.0
    },
    {
      "text": " Yes we should",
      "start_time": 3134.0,
      "end_time": 3136.0
    },
    {
      "text": " Which one?",
      "start_time": 3136.0,
      "end_time": 3138.0
    },
    {
      "text": " Which one?",
      "start_time": 3142.0,
      "end_time": 3144.0
    },
    {
      "text": "",
      "start_time": 3148.0,
      "end_time": 3120.0
    },
    {
      "text": " I am not, it's not recognizing.",
      "start_time": 3125.5,
      "end_time": null
    },
    {
      "text": " It is not appearing that is what mine also is not appearing.",
      "start_time": 3150.0,
      "end_time": 3163.7
    },
    {
      "text": "",
      "start_time": 3163.7,
      "end_time": 3150.0
    },
    {
      "text": " Assum raisins Sujay this one no?",
      "start_time": 3152.0,
      "end_time": 3154.0
    },
    {
      "text": " It's connected no?",
      "start_time": 3158.0,
      "end_time": 3160.0
    },
    {
      "text": " Okay, let's look at the demo.",
      "start_time": 3180.0,
      "end_time": 3207.86
    },
    {
      "text": "",
      "start_time": 3207.86,
      "end_time": 3180.0
    },
    {
      "text": " I have connected it to...",
      "start_time": 3182.0,
      "end_time": null
    },
    {
      "text": " with a teacher teacher inside. So, I have given the prompt like this classroom with",
      "start_time": 3210.0,
      "end_time": 3222.68
    },
    {
      "text": " a teacher is the prompt. So, when we run it it goes through all the embedding all the",
      "start_time": 3222.68,
      "end_time": 3227.92
    },
    {
      "text": " process and it generating the image. Can I have your attention please silence last bench",
      "start_time": 3227.92,
      "end_time": 3234.04
    },
    {
      "text": "",
      "start_time": 3234.04,
      "end_time": 3210.0
    },
    {
      "text": " Thank you.",
      "start_time": 3212.0,
      "end_time": null
    },
    {
      "text": " Let us see what kind of image gets generated.",
      "start_time": 3240.0,
      "end_time": 3247.0
    },
    {
      "text": " So, if you look at this is the image generated.",
      "start_time": 3247.0,
      "end_time": 3258.68
    },
    {
      "text": " So, if you look at the artifacts, see look at the image faces, this is stable diffusion",
      "start_time": 3258.68,
      "end_time": 3264.48
    },
    {
      "text": "",
      "start_time": 3264.48,
      "end_time": 3240.0
    },
    {
      "text": " which means that there is lot of work to be done here in this area.",
      "start_time": 3245.52,
      "end_time": null
    },
    {
      "text": " Even the stable diffusion with all the process that it said, what is happening?",
      "start_time": 3270.0,
      "end_time": 3286.48
    },
    {
      "text": "",
      "start_time": 3286.48,
      "end_time": 3270.0
    },
    {
      "text": " with a teacher, so I will write Indian conditions. Let us see.",
      "start_time": 3277.0,
      "end_time": 3282.0
    },
    {
      "text": " you",
      "start_time": 3300.0,
      "end_time": 3302.06
    }
  ],
  "transcript_text": " types of inputs in generating of embeddings that is called as a multimodal LLM.  So here clip accepts image text pairs, image text pairs.  See there is slight deviation from the original idea that is it but it has become very popular.  You must have heard about clip blip and all of that right but it became popular.   What did they do? I will tell you now, just now.  Just in a minute.  So here they have used a vision transformer.  They have used a vision transformer.  What is a vision transformer?  We have studied already.  What is it?  Given an image, it fits it into patches.  Transformer it expects sequence.  This you should remember forever.  Transformer means it is a sequence to sequence model.  We should give some sequence to transformer.  To give a sequence, image is not a sequence basically.   How do you convert?  an image into a sequence, piece it, scissor it and then make the sequence and produce  that sequence. So, image sequence is given, image sequence is given and it produces image  embeddings, image embeddings. This is one architecture used in clip. On the other side,   uses GPT kind of architecture decoder, GPT type of decoder.  and text prompt is given and it produces text embeddings. Text embeddings are produced  to architectures separately in the clip model and these image embeddings and text embeddings  let us say we are giving the image of a cat, image of a cat and the text is also saying   cat image, text is also saying cat image. So the embedding generated by this is the  these two should be close they have to match right it is a match pair image and text match  pair so if it is not matching it will retrain saying that these embedding should come closer  to each other so checks the cosine similarity between the two that is why it is called as  contrastive learning cosine similarity between the text embedding and image embedding and  if it is not close to one there is lot of error because we know that we have given matching   Catty made it.  we gave and the text is also cat image the two embedding should be close if the two embeddings  are not close then there is high loss, high loss will backtrane back propagate and train  so that the loss between the two embeddings is reduced what does that mean it learns the  equivalent text embedding and image embedding it brings them to same space that is what  the clip is trying to learn suppose I give that this is a dog image dog image is a text   from but what I am giving.  is a cat and now you check whether the embedding are really dissimilar or not. If they are  actually very similar then there is again there is a loss. So you train so that they  become far apart. So for similarity you can keep it 1 for dissimilarity you can keep it  0 any output you can keep. So if they are not close to this if they are similar they  have to be close to 1. If they are not close to 1 there is a loss if they are dissimilar   information they have to be close to 0. If they are not close to 0, then they will be  to 0 again there is a loss. So, like this they gave similar pairs dissimilar pairs like  this a lot of may be 1 k 2 k 2 lakh I am saying 2 lakh images and then they trained this transformer  this is how clip is trained. Now, once the clip is trained now you can give  that just the text and the text embedding generated would be in the space similar to  that of the image. Do you understand the difference between the bird embedding and this also text   next time meeting it can do.  So, once the clip is ready you can just give text prompt and you can get the text embeddings.  What is the difference between clips text embedding and birds, birds same text what is  the difference the embedded same sentence let us say cat image cat image to bird cat  image to clip if you give the embedding generated by the clip will be similar to image embedding   Thanks, babe.  The two embeddings will not be same.  The training tasks are different.  Do you understand?  The BERT has been trained only on missing word prediction.  The way the embeddings are generated by BERT is totally different.  For the same sentence, do you understand the difference and can you appreciate?  It is very important on what they have been trained on, what is the task at which they  are good at.   based on that only they will produce embedding.  Although the sentences are same, the kind of embedding produced by BERT would be very  different from the embedding produced by CLIP and the CLIP embedding would be close to image  type of embedding.  So you should know if you are operating in image related applications, the text prompt  embedding should be close to image related embedding.  You cannot use a BERT there.  You understand when you give a text prompt and you want it to be converted into an embedding   and you are using that for generating an image.  Don't you think we should use clip now?  Do you understand what I am saying?  So the kind of prompt you gave cat image, cat image, here also cat image but this produce  0.1, 0.2, this may produce 0.6, 0.5.  The two embeddings are different because the training that has been given is different.  You get what I am saying?   The 0.6, 0.5 will be similar to that of image embedding which is\u2026  And if you are talking about image applications you should use such pre-trained models.  Now you understand hopefully which pre-trained model you should choose is not just like that  some pre-trained model.  Your first understanding should be what is it trained on?  Is it going to serve my purpose or not?  Do you understand?  Lot of pre-trained models are available.  Just like that you cannot pick up something.   I use the VGG, I use the ResNet like that you use.  It is not generic, you have to decide what task it is trained on whether it is going  to suit my application or not.  Then it will be closer not that the bird will not work but those embeddings will be far  away from your image embeddings.  They may not really serve the purpose so much.  So that is the importance of which pre-trained model.  Pre-training means that you should know the task on which it is pre-trained so that you   know what kind of embedding get generated from  the pre-trained model and whether those embeddings will make sense in my application or not and  based on that you should proceed further.  Is this clear?  Okay.  So, is clip clear?  So, the pre-trained clip model is used in generating text embedding.  Why is clip used here?  Because our job is to generate image.  I want the text embedding close to image embedding.  So, clip is used.   So second step in the stable diffusion is to send this text from  to clip and generate text embeddings. This is the second step. Now the third step is   third step, text time bidding and the latent vector.  is produced given to unit. The latent vector and the text embedding both are given to the  unit architecture, both are inputs and what is the job of the unit? It produces noise   prediction.  That is the third step in stable diffusion.  Unit architecture receives two inputs latent vector with noise and then text embedding   and produces noise predictions.  How is the text embedding going to help? Suppose text embedding is that of a car, text embedding  is that of a cat. So the amount of noise that you have to remove, so if it is a car latent  vector, I am writing the image itself, it is in car I do not know how to write, some  car I am writing. This is a car, my cat and car both look similar. This is a cat.   Thank you.  This is the car, horribly looking like car, not good at writing 3D diagram is looking  like a house, some wheels I will put maybe it will look like a car.  This is the car, this is the cat, okay.  I am not showing it in late and trekker space, I am showing it in image space, okay.   So the way I am adding noise here, I have added noise here.  noise and I am feeding that to unit I am feeding that to unit now the kind of the way you have  to remove noise from car the way you have to remove noise from cat they are different  do you understand where you have to remove that noise and where you have to remove noise  from car they are two different so to guide that process this conditioning is used the   Extend coding will help how to remove noise for  how to remove noise for car. Of course it is back propagated if the noise removed is  not same as car noise removal then back propagation is done and error correction is done. But  you need to understand that text embedding is conditioning the unit to say that you remove  the noise from this image to make sure that car image is going to be visible.  You remove the noise from this image so that the cat is going to come up. The kind of noise   removal that you do from can.  that is not the same as noise removal that you do it from car.  So, to guide that process this text embedding will help, but apart from that it is a black  box it does there is magic it is the magic is always in the back propagation if it is  not doing that correctly you are going to back propagate at least you know that there  is error it is not doing it properly you know.  So you back propagate and somehow it is able to converge to a point where car becomes visible   inside unit but what it produces is how much not.  noise I should remove if it is carved noise. How much noise I should remove if it is that  of a cat image and noise. So it predicts the noise based on the image and the text embedding.  The noise to be removed is dependent on the kind of image that is going to be present.  So that is the job of the unit. The unit architecture goes like this. This is convolutions, this   is deconvolution this is a use factor that is why it is known as a use factor.  unit architecture okay and this is convolution and latent vector, from latent vector it tries  to produce the image back and if it produces the image same as the original image with  minus noise, noise will be predicted.  So output of the convolution unit architecture is noise, not the noise removed image but  it does that internally, it will remove the noise and it will compare all of that it does   but the units in this section are not there.  example I am saying unit is not always used for that purpose. In this stable diffusion  the purpose of unit is to predict how much noise is present in this image and that noise  is varying even though you add similar amount of noise the noise removal is a process dependent  on the structure within the image. So based on that it predicts the noise.  So eventually when you expose this unit to many images many schedules of the noise of   the same image.  image, it will eventually learn how to remove noise without disturbing the underlying structure  that is what it learns. This is clear, this is the training process, this is clear, this  is the unit architecture. So now we will have to proceed to the testing   phase actually how it generates the image.  So, I produce image EIE then latent vector then add noise.   Thank you.  Then unit.  That's nice.  Unit.   and then we'll go back to the beginning. And then we'll go back to the beginning.  And then we'll go back to the beginning.  And then we'll go back to the beginning.  And then we'll go back to the beginning.  And then we'll go back to the beginning.  And then we'll go back to the beginning.  And then we'll go back to the beginning.  And then we'll go back to the beginning.  And then we'll go back to the beginning.  That is your forward process.  Image, go through VAE, produce the latent vector, then add the noise as per the schedule  and then produce, send it to unit and text prompt, send it to clip, text embedding and  then send it to unit, noise prediction.   Now the second step, second step is to get the first step.  One step is the iteration for the same image, iteration for the same image starts here,  another schedule of the noise of the same image, this process is not continued again  for the same image.  So, image 1, L1, L2 up to LT, different noises are added and then you continue this process.   So that second image you take, then you take the second image start from here.  And then this is how you train it, is this clear?  So once the LV is obtained, many schedules of the noise here you have to train on the  same image.  This is repeated many times and unit is trained.  Then second image like this it gets trained on several lakhs of images with different  noise schedules.  So it is able to now predict how much noise is there in an image.   That is a capability that...  unit is building. It is given a noisy image, it knows how to expect the amount of noise  that is present in it without disturbing the structure. So, it produces that.  Now, we will look at the reverse. So, in the reverse process, what is our objective finally?   to generate an image.  So, prompt I will give you, I will say generate a cat image, generate a cat image, this is  the prompt as usual this will go through clip, this will give you text embedding, text embedding.  This process remains the same during the generation phase, I will say to the stable diffusion   model generate a cat image. But now you have to generate  from the Gaussian distribution a latent vector. So a latent vector has to be generated which  is a noisy latent vector, noisy latent vector based on a Gaussian distribution. It is proven  that Gaussian noisy distribution sample would yield better images. Any other distribution  you could have taken but that is for your experimentation. But a noisy latent vector   has to be created from a Gaussian distribution sample. One sample has to be generated.  So, that you give it to already trained unit, already trained unit.  So, there is text embedding, it is not simply removing some noise.  So, this predicts what, how much noise is there in the latent vector based on the text  embedding, that is a beauty, it is not just noise.  So, it is conditioned based on this.   So how much is how much noise is there in this latent vector?  vector based on this embedding. So, it predicts the noise, predicts the noise N1. Next what  you should do? I have not a generated image, I have just predicted the noise that is present  in latent vector based on my text embedding guidance. Now, I am supposed to subtract this   noise n 1 from this l 1 this is l 1. So, l 1 minus n 1.  will produce L2, L1 minus N1 will produce L2 and what I should do now? This is the reverse  diffusion process, pure noise image is converted into a slightly better picture now which is  L2. This is pure noise image, pure noise vector and this is better quality less slightly   Ready?  less than noise compared to L1 slightly lesser noise because we have subtracted this noise  okay. Now I am going to feed L2 but your text form continues to be the same. Now I feed  L2 so again noise is predicted this time it is N2. So now what I should do L2-N2 you produce   This you do it for several steps.  Do you understand?  You do this for several steps.  When you do this for several steps, you may get LT.  Finally LT, some T steps you have done.  So first time pure noise vector, you feed it to unit, produce, predict the noise and subtract  the noise from L1 and then feed the lesser noise latent vector back again to unit.   it will predict the noise like this.  if you keep on doing for several steps may be t steps final latent vector you are satisfied  may be after 100 steps you are satisfied with the latent vector LT but that is not an image.  LT is the final latent vector generated out of the last noise removal LT is your final  latent vector what is the next step? LT should be fed to decoder of VAE you should feed it   to decoder of VAE to generate the  actual image cat. These are the steps, is the process clear?   Thank you.  This is called as stable diffusion using latent diffusion models.  I will give you a minute time now see whether you understood all the steps that I explained.  What happens during training?  What happens during testing or generation?  Testing is generation.   They are two different steps.  What is for, see you should understand, answer these questions, what is diffusion, what is  forward diffusion, what is reverse diffusion, characteristic equation related to diffusion,  these 5 things related to diffusion.  Then what is latent diffusion and how latent diffusion is used in stable diffusion.  Stable diffusion is a image generation engine.  To do that it uses 3 steps, what is VAE, what is its role, what is the encoder of VAE, what   What is the decoder of VIA?  Then you should know the second step of VAE, I mean second step of stable diffusion which  is clip.  What is a clip which is a multi-modal LLM, what it does, how it is trained, what is it  good at, how the embeddings are created, all of that in the clip.  And then clip is used for text embeddings and how text embedding at this is used for  unit, how the noise prediction happens, how the unit is built during training phase to  predict noise that is training, then generation.   how the unit is fed with Gaussian.  latent vector that is generated noise vector and the text prompt embedding and how that  is fed, noise is predicted, subtract it latent vector, feed it again, feed it again, feed  it again, subtract feed it, subtract feed it and then produce final latent vector then  to the decoder and then produce the image. This is the full step. So figure out whether   you understand all of these steps.  If you understand all of that I said today, you will be able to answer properly the examinations.  Everything about stable decision I have completely explained, this is all you need to know.   I will just come get my laptop you can take a break also.  I'm going to go back to the room.  Okay.  I'm going to go back to the car.  I'm going to go back to the  back of the  back of the  back of the back of the back of the  back of the back of the back of the  back of the back of the back of the  back of the back of the back of the  back of the back of the back of the  back of the back of the back of the  back of the back of the back of the  back of the back of the back of the  back of the back of the back of the  back of the back of the back of the  back of the back of the back of the   Thank you.  Okay.  .  The  I'm going to go back to the car.  I'm  I'm  I'm  I'm   Thank you.  Thank you.  .  .  .  .   Thank you.  I'm going to go back to the  back of the  back of the  back of the back of the  back of the back of the  back of the back of the  back of the back of the  back of the back of the  back of the back of the back of the  back of the back of the back of the  back of the back of the back of the  back of the back of the back of the  back of the back of the back of the  back of the back of the back of the   Thank you.  Please answer your attendance.  Anmita, Aryan, Bhavana, Bhavana, Bhumika, Bhumika, Hemchandra, Chaitra, Chandana, Chandana,   Chinmai, Darshan, Dhruv, Dhiya, Fiza, Kaorish,  Harshil, Harshini, Hemanta, Ritika, Ishaan, Vignesh, Amrita, Kishore, Manoj, Mohit,   Yes. Nikhil.  Nisha.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Nikhil.  Vishan, Chiru, Piyush, Rajul, Ranjal, Priyanka, Priyansh, Diksha, Rajit, Rahul,   Thank you.  Rohan, Kachi, Sri Hari, Sushrit, Siddharth, Siddharth, Saurabh, Sujay, Sujit, Sukhi,   Sai Shridhar, Jagapati, Yash Nagraj  Asha Svii Ni, Arpita, Sarvad Nya, Ishwari, Nithika, Nithika B. Vinay,   Yes, Akshay, Om Mathur, Mithun Kumar, Pushkar.  Smira, baceuraj?  and  the  The correct equation is the given letter.  The correct equation is given letter for the equation.  I will put the same as the one in the hand.   and we are like renewing the noise from the lately matter. How do you know how many times we had to...  like do we check it with me or like is it a hyper parameter?  That is a hyper parameter.  How many, what is the noise schedule that you have to decide?  How come Saurabh shifted there?   Thank you.  After the paper presents, after that he is there only.  No one present, why?  No.  Because I wrote, I knew that if I write an email like that it would happen.   There will be no control.  If I do not inform also it is not correct, but I knew that if I inform many will skip.  But that was 11.30 am now, but in between they skipped.  In between also they skipped is it.   Good morning, you...  No, 11.30, no, because morning you had to come.   Thank you.  I'm going to go back to the  room.  I'm going to go back to the  room.  I'm going to go back to the  room.  I'm going to go back to the  room.  I'm going to go back to the  room.  I'm going to go back to the  room.  I'm going to go back to the  room.   Thank you.  Thank you.  Thank you.  .  .  .  .   Thank you.  the  I'm not sure.  The  the  Thank you.  Thank you.  the  the  So, let us look at this continue there is a stable diffusion demonstration let us look   get that.  So, this is the hugging phase demonstration site. So, we will say classroom with a teacher.  I am giving the text from I told you it goes through the clip. So, I am asking it to generate   classroom with a teacher. You are all doubt.  Again I will run it.  I'm going to turn it off.  Wifi issues are there.  Wifi is gone then.   Wifi is gone then  the  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.  Hello.   I don't know.  classroom normally 4th floor  then demo mode is not working  the  Thank you.  I'm  the  Thank you.  It is not working.   spot is also not working.  Thank you.  In the meantime, can I have your attention?  I think this is already cached so it is appearing, the network is down so I am not able to connect  to hotspot also.   So, this is the stable diffusion stable art website.  So this is the forward diffusion process.  So cat image dog image forward diffusion this is the noise.  So you can see that forward diffusion this is how it works.  Are you able to see this?  So cat is slowly blurred and you get a noisy image and in the reverse diffusion now it   It is not cashed.  Thank you.  Okay.  Okay  There are classes for Manaka  Your hotspot can I connect?  Yes we should  Which one?  Which one?   I am not, it's not recognizing.  It is not appearing that is what mine also is not appearing.   Assum raisins Sujay this one no?  It's connected no?  Okay, let's look at the demo.   I have connected it to...  with a teacher teacher inside. So, I have given the prompt like this classroom with  a teacher is the prompt. So, when we run it it goes through all the embedding all the  process and it generating the image. Can I have your attention please silence last bench   Thank you.  Let us see what kind of image gets generated.  So, if you look at this is the image generated.  So, if you look at the artifacts, see look at the image faces, this is stable diffusion   which means that there is lot of work to be done here in this area.  Even the stable diffusion with all the process that it said, what is happening?   with a teacher, so I will write Indian conditions. Let us see.  you"
}